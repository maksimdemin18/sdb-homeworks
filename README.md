# Домашнее задание к занятию "`Базы данных, их типы`" - `Дёмин Максим`


### Задание 1

Что нужно сделать:

СУБД
Кейс
Крупная строительная компания, которая также занимается проектированием и девелопментом, решила создать правильную архитектуру для работы с данными. Ниже представлены задачи, которые необходимо решить для каждой предметной области.

Какие типы СУБД, на ваш взгляд, лучше всего подойдут для решения этих задач и почему?

1.1. Бюджетирование проектов с дальнейшим формированием финансовых аналитических отчётов и прогнозирования рисков. СУБД должна гарантировать целостность и чёткую структуру данных.

1.1.* Хеширование стало занимать длительно время, какое API можно использовать для ускорения работы?

1.2. Под каждый девелоперский проект создаётся отдельный лендинг, и все данные по лидам стекаются в CRM к маркетологам и менеджерам по продажам. Какой тип СУБД лучше использовать для лендингов и для CRM? СУБД должны быть гибкими и быстрыми.

1.2.* Можно ли эту задачу закрыть одной СУБД? И если да, то какой именно СУБД и какой реализацией?

1.3. Отдел контроля качества решил создать базу по корпоративным нормам и правилам, обучающему материалу и так далее, сформированную согласно структуре компании. СУБД должна иметь простую и понятную структуру.

1.3.* Можно ли под эту задачу использовать уже существующую СУБД из задач выше и если да, то как лучше это реализовать?

1.4. Департамент логистики нуждается в решении задач по быстрому формированию маршрутов доставки материалов по объектам и распределению курьеров по маршрутам с доставкой документов. СУБД должна уметь быстро работать со связями.

1.4.* Можно ли к этой СУБД подключить отдел закупок или для них лучше сформировать свою СУБД в связке с СУБД логистов?

1.5.* Можно ли все перечисленные выше задачи решить, используя одну СУБД? Если да, то какую именно?

Приведите ответ в свободной форме.

### Решение:

1.1. Бюджетирование проектов + фин. отчёты + прогнозирование рисков

Требования: строгая структура, целостность, понятные связи, не потерять деньги - нужна транзакционность.

Лучший выбор: реляционная СУБД (OLTP) + отдельно аналитика (OLAP)

Для бюджетов/платежей/договоров: PostgreSQL / MS SQL Server / Oracle

(ACID-транзакции (чтобы суммы/проводки не “плыли”), ограничения, ключи, схемы (целостность данных), удобные JOIN, отчётность, аудит)

Для аналитических отчётов и прогнозов (BI/риски):

(либо DWH/колоночная СУБД (ClickHouse / Vertica / Snowflake), либо аналитический контур на той же экосистеме.)

Почему:

отчёты и агрегации по большим объёмам в колоночных системах быстрее и удобно строить витрины, фичи для ML и прогнозов

Итого по архитектуре (просто):

PostgreSQL быстрые аналитические отчёты.

1.1.* Для паролей (медленно стало из-за большой нагрузки):

Argon2id (часто лучший современный выбор) или bcrypt/scrypt через стандартные крипто-библиотеки.

Для быстрого хеша (не для паролей, а для дедупликации/контроля целостности):

BLAKE3 (очень быстрый), либо SHA-256 с аппаратным ускорением.

Что именно можно назвать “API” в практическом смысле:

OpenSSL (EVP API) - часто даёт ускорение за счёт оптимизаций и аппаратных инструкций.

Если речь про прикладной уровень: вынести хеширование в отдельный сервис и дергать по gRPC (быстрее и экономнее, чем JSON/HTTP при больших объёмах).

Если узкое место в Python - использовать реализации на C/Rust (например, библиотеки для Argon2/BLAKE3), а не “чистый Python”.

1.2. Лендинги (лиды) - CRM (маркетинг/продажи)

Требования: гибко (формы разные), быстро (много лидов), легко масштабировать.

Для лендингов (сбор лидов, события, формы)

Подходит: документная NoSQL (MongoDB) или ключ-значение/лог событий (Redis/Kafka как транспорт), но хранить всё равно где-то нужно.

Почему MongoDB:

формы у разных проектов могут отличаться - гибкая схема

быстро писать события/лиды

можно хранить “как пришло” (utm, поля, доп.данные)

Для CRM (сущности: клиенты, сделки, статусы, активности)

Лучше: реляционная СУБД (PostgreSQL / MS SQL)

Почему:

CRM почти всегда про связи: клиент - сделки - задачи - коммуникации

нужны транзакции, права, отчётность, целостность

Итого: лендинги - NoSQL как “приёмник”, CRM - SQL как “система записи”.

1.2.* Самый реалистичный “одной СУБД” вариант - PostgreSQL:

Как реализовать:

CRM - обычные нормализованные таблицы

Лиды с лендингов:

либо отдельные таблицы (структурировать ключевые поля + доп.поля)

доп. поля складывать в JSONB (в Postgres это удобно и быстро)

Индексация:

индексы на основные поля (phone/email/utm/source)

GIN-индексы на JSONB для поиска по динамическим атрибутам

Плюсы:

одна точка администрирования, бэкапы, права

транзакции везде

Минусы:

нужно аккуратно проектировать, иначе “свалка в JSON”

1.3. База корпоративных норм, правил, обучающих материалов (по структуре компании)

Требования: простая структура, понятно пользователям, иерархия (подразделение - документы - версии).

Лучший выбор: реляционная СУБД (или даже CMS поверх неё)

PostgreSQL/MySQL + таблицы:

Departments (подразделения)

Documents (документы)

Versions (версии)

Tags (теги)

Почему:

структура “дерево/каталог” легко моделируется

поиск, права доступа, версии - всё удобно

А если акцент именно на “поиск по тексту”:

хранить метаданные в SQL, а полнотекст - через Elastic/OpenSearch (как доп. компонент).

1.3.* Если у компании уже есть PostgreSQL для 1.1/CRM, то базу норм лучше сделать в том же PostgreSQL, но:

отдельная схема (schema) или отдельная БД в том же кластере

раздельные роли/права

желательно отдельные таблицы и регламент по версиям документов

Так будет проще сопровождать, а структура останется “понятной”.

1.4. Логистика: маршруты, курьеры, быстрые связи

Требования: “быстро работать со связями” и, по сути, графовые задачи (маршруты, оптимизация).

Лучший выбор: графовая СУБД (для связей) + SQL (для транзакций)

Neo4j / JanusGraph / TigerGraph

Почему:

маршруты, узлы, ребра, ограничения - естественная модель графа

запросы типа “найди оптимальный путь/ближайшие точки/варианты маршрутов” удобнее

Но: реальная логистика обычно ещё требует:

заказы/накладные/статусы/акты - SQL (PostgreSQL)

Итого: граф - для вычислений связей и маршрутов, SQL - для учёта.

1.4.* Подключать закупки туда же или лучше отдельно?

Зависит от того, что именно нужно закупкам:

Если закупкам важно видеть логистические ограничения (сроки доставки, доступность маршрутов, склады) - можно подключить к той же экосистеме, но:

закупки как учёт (заявки, договоры, счета) лучше держать в реляционной СУБД

Практичный вариант:

единый Postgres как “учётная часть” (закупки + логистика-учёт)

графовая БД как “расчётная часть” (маршрутизация, оптимизация)

синхронизация по ключевым справочникам (склады/объекты/дороги/ограничения)

Так закупки не “ломают” граф, и граф не становится бухгалтерией.

1.5.* Теоретически да, практически “одной” будет компромисс.

Самый реалистичный кандидат: PostgreSQL

Почему:

закрывает строгую целостность (1.1)

тянет CRM (1.2)

тянет базу норм (1.3)

для логистики можно частично:

хранить граф как таблицы + рекурсивные запросы (CTE)

использовать расширения/геоданные (PostGIS) для координат и расстояний
 но полноценная графовая оптимизация всё равно будет сложнее, чем в Neo4j

Да, одной можно - PostgreSQL (CRM + бюджеты + корпоративная база + лиды через JSONB, логистика частично через PostGIS/CTE).


### Задание 2. 

Что нужно сделать:

Транзакции

2.1. Пользователь пополняет баланс счёта телефона, распишите пошагово, какие действия должны произойти для того, чтобы транзакция завершилась успешно. Ориентируйтесь на шесть действий.

2.1.* Какие действия должны произойти, если пополнение счёта телефона происходило бы через автоплатёж?

Приведите ответ в свободной форме.

### Решение:

2.1. Пополнение баланса телефона - 6 действий, чтобы транзакция прошла успешно

Создание операции (инициация)

Пользователь вводит номер телефона, сумму, выбирает способ оплаты.

Система создаёт черновик операции пополнения: payment_id, статус NEW/CREATED, фиксирует параметры (номер, сумма, комиссия, время).

Проверки и валидация

Проверяется формат номера, допустимость суммы, лимиты/антифрод-правила, доступность провайдера (оператора).

При необходимости - проверка пользователя (3-D Secure/OTP), если оплата картой.

Авторизация платежа у платёжного провайдера

Система отправляет запрос в платёжный шлюз/банк на холд/авторизацию суммы (резервирование).

В БД фиксируется результат: AUTHORIZED или FAILED с причиной.

Проведение пополнения у оператора связи

После успешной авторизации система отправляет запрос оператору (или агрегатору) на пополнение.

Важно: операция должна быть идемпотентной (по payment_id), чтобы при повторной отправке не было двойного зачисления.

Фиксация результата и списание (capture)

Если оператор подтвердил зачисление, система делает capture в платёжном шлюзе (окончательно списывает деньги).

В БД транзакция коммитится: статус SUCCESS, сохраняются все ссылки/квитанции/референсы (bank_rrn, operator_txn_id).

Уведомление и финальные записи

Пользователю показывается успешно, отправляется чек/смс/пуш.

Логи, аудит, проводки, отчётность: запись в журнал, обновление баланса/истории операций.

2.1.* Если это автоплатёж — какие действия добавляются/меняются

Автоплатёж отличается тем, что перед 6 шагами появляются подготовительные и фоновые действия, а пользователь не инициирует вручную каждый раз.

Что должно происходить:

Настройка автоплатежа (один раз)

Пользователь задаёт правило: номер, сумма/порог, периодичность, лимиты.

Сохраняется шаблон автоплатежа и его параметры.

Сохранение платёжного метода

Карта/счёт привязывается через токенизацию (хранится токен, не номер карты).

Возможна настройка 3-D Secure “по правилам” банка: иногда требуется подтверждение при первой привязке.

Триггер выполнения

По расписанию (раз в месяц/неделю) или по условию (баланс ниже порога) система запускает автоплатёж.

Создаётся операция payment_id со статусом CREATED (как в ручном варианте).

Проверки автоправил

Проверка лимитов автоплатежей (дневной/месячный), антифрод, активность шаблона, доступность токена.

Если нарушены правила — автоплатёж не выполняется, ставится статус SKIPPED/FAILED, уведомление пользователю.

Дальше идут те же боевые шаги, что и в 2.1

Авторизация у банка - запрос оператору - capture/коммит - уведомление.

Пост-обработка

Обновление статистики автоплатежа (сколько раз, на какую сумму), возможная пауза автоплатежа при повторных ошибках.

Нотификация пользователю: автоплатёж выполнен или не выполнен, причина.


### Задание 3. 

Что нужно сделать:

SQL vs NoSQL

3.1. Напишите пять преимуществ SQL-систем по отношению к NoSQL.

3.1.* Какие, на ваш взгляд, преимущества у NewSQL систем перед SQL и NoSQL.

Приведите ответ в свободной форме.

### Решение:

3.1. Пять преимуществ SQL-систем по отношению к NoSQL

1) Жёсткая схема и целостность данных (constraints)

В SQL (PostgreSQL, MS SQL, MySQL и т.д.) можно заранее описать структуру таблиц: типы полей, обязательность, связи между сущностями.

Плюс есть ограничения:

PRIMARY KEY, FOREIGN KEY

NOT NULL, UNIQUE

CHECK (например, сумма ≥ 0)

За счёт этого данные меньше разъезжаются и проще гарантировать, что в базе нет противоречий. В NoSQL часто схема гибкая, и контроль целостности приходится 
писать в приложении.

2) Транзакции ACID из коробки

SQL-СУБД традиционно сильны в транзакционности:

атомарность

согласованность

изоляция

долговечность

Это критично для денег, заказов, остатков, бухгалтерии, CRM — где нельзя допустить частично записанные данные.

В NoSQL транзакции могут быть ограничены или сложнее в настройке и использовании.

3) Мощные запросы и JOIN’ы (сложная аналитика на данных)
   
SQL удобен, когда надо делать сложные выборки:

JOIN между множеством таблиц

группировки GROUP BY

оконные функции (OVER, ROW_NUMBER, SUM() OVER(...))

подзапросы, CTE

В NoSQL обычно лучше работает модель получить документ целиком, а сложные связи и агрегации либо дороже по производительности, либо делаются на стороне 
приложения.

4) Стандартизация и переносимость

SQL — это стандартный язык запросов.

Если ты умеешь SQL, то с небольшими отличиями сможешь работать в разных СУБД. Это снижает “привязку” к конкретному вендору и облегчает обучение команды.

В NoSQL у каждой системы часто свои подходы: разные языки запросов, разные модели данных, разные механики индексации и репликации.

5) Зрелость экосистемы и инструментов (администрирование, бэкапы, аудит)

SQL-мир очень зрелый:

понятные стратегии бэкапов/репликации

большое количество BI-инструментов

удобные средства аудита и контроля доступа

хорошо описанные best practices

NoSQL тоже развивается, но часто требует больше “инженерной дисциплины” и специфических знаний под конкретную СУБД.

3.1.* Преимущества NewSQL перед SQL и NoSQL

NewSQL — это попытка взять лучшее от двух миров:

как у SQL: реляционная модель, SQL-запросы, ACID

как у NoSQL: горизонтальное масштабирование, высокая доступность, работа на кластере

Примеры: CockroachDB, Google Spanner, YugabyteDB, TiDB и др.

1) Масштабирование “как у NoSQL”, но с транзакциями и SQL

Классические SQL часто масштабируются вертикально (сильный сервер) и репликами на чтение.

NewSQL изначально проектировались под распределённый кластер:

добавляешь ноды, растёт производительность и объём

при этом сохраняются ACID-транзакции и привычный SQL.

2) Высокая доступность и отказоустойчивость по умолчанию
3) 
NewSQL обычно умеет:

автоматическую репликацию данных

переживать падение нод

автоматически перевыбирать лидеров/реплики

геораспределение 

То есть меньше ручной боли при построении always-on систем.

3) Меньше компромиссов CAP: ближе к Консистенции без потери распределённости

Многие NoSQL ради масштабируемости уходят в eventual consistency.

NewSQL чаще пытается дать сильную согласованность в распределённой системе, пусть и ценой более сложной внутренней архитектуры.

5) Проще для разработки корпоративных систем

Для бизнеса часто важно:

сложные связи (CRM, финансы)

отчётность

транзакции

ограничения целостности

NewSQL позволяет всё это делать привычно, не переписывая логику на костылях, как иногда приходится в NoSQL.

5) Удобно, когда нужен рост, но уже есть SQL-команда

Если команда уже умеет SQL и модель данных реляционная, NewSQL позволяет:

не менять сильно подход к разработке

при этом получить масштабирование и HA уровне платформы

Но честно: минусы тоже есть дороже и сложнее в эксплуатации (кластер, сеть, консенсус)

требования к latency (в распределённых транзакциях задержки могут быть выше)

не всегда быстрее классического SQL на одной мощной машине

Мини-вывод:

SQL - лучший выбор, когда важны целостность, сложные связи, транзакции и всё помещается в разумные масштабы.

NoSQL - когда важна гибкость схемы и скорость записи/чтения под конкретные кейсы (логирование, документы, кэш, события).

NewSQL - когда хочется SQL + ACID, но при этом нужна кластерность и горизонтальное масштабирование.

### Задание 4. 

Что нужно сделать:

Кластеры

Необходимо производить большое количество вычислений при работе с огромным количеством данных, под эту задачу выделено 1000 машин.

На основе какого критерия будете выбирать тип СУБД и какая модель распределённых вычислений здесь справится лучше всего и почему?

Приведите ответ в свободной форме.

### Решение:

1) По какому критерию я бы выбирал тип СУБД (главные критерии)

Критерий №1 - Тип нагрузки: OLTP или OLAP (и какая аналитика)

OLTP (много коротких транзакций: покупки, платежи) - нужны ACID, низкая задержка.

OLAP (много тяжёлых запросов/агрегаций/сканов) - нужны колоночные форматы, параллельное выполнение, дешёвое чтение больших объёмов.

Раз у нас много вычислений на огромных данных, обычно это OLAP / Big Data аналитика, значит:

лучше колоночные и распределённые решения,

плюс отдельно движок вычислений.

Критерий №2 — Какой нужен SLA по времени ответа

Если нужны интерактивные отчёты здесь и сейчас - одно.

Если это тяжёлые батчи ночью посчитать - другое.

На 1000 машин часто считают либо:

интерактивную аналитику по витринам,

либо массовые батч-вычисления/ML.

Критерий №3 — Как данные будут распределяться

Важно понять:

по какому ключу данные делятся (дата, клиент, регион, проект)

сколько будет перекрёстных запросов (join между шардами)

нужен ли баланс нагрузки

Если запросы в основном по датам - хорошо партиционировать по времени.

Если часто по клиентам/объектам - шардирование по id.

Критерий №4 - Отказоустойчивость и консистентность

На 1000 машин падения - это норма, а не ЧП, поэтому:

нужна репликация,

автоматическое восстановление,

возможно, eventual consistency (если допустимо),

или strong consistency (если это критично).

Критерий №5 - Формат данных и тип вычислений

Если много сканов, агрегаций, фильтров - колоночные форматы (Parquet/ORC) и MPP.

Если много графовых связей - отдельные графовые движки.

Если много потоковых событий - streaming + хранилище под события.

2) Какой тип СУБД под 1000 машин подходит лучше (по сути)

Вариант A (часто самый правильный для очень много данных): Data Lake + вычислительный движок

Хранилище: распределённое файловое (HDFS / S3-совместимое object storage)

Формат: Parquet/ORC (колоночный)

Слой таблиц: Hive Metastore / Iceberg / Delta Lake (чтобы было как таблицы)

Плюс: дешёвое масштабирование, удобно хранить петабайты.

Это не одна СУБД, а платформа, но на 1000 машин это часто топовый подход.

Вариант B: MPP-колоночная распределённая СУБД (когда нужен SQL и скорость)

Примерно идея: раскидали данные по нодам и параллельно считаем SQL.

Подходящие типы:

MPP-аналитические СУБД (Greenplum/Vertica/ClickHouse-кластер и т.п.)

Плюсы:

интерактивные запросы быстрее

много готового SQL

Минусы:

дороже и сложнее масштабирование до реально огромных объёмов

нагрузка тяжёлые джойны + много пользователей может быть сложной

Вариант C: NewSQL (если это всё же транзакционность + масштаб)

Если задача была бы: много данных + транзакции + нужна консистентность в кластере, тогда:

NewSQL (типа CockroachDB/Spanner-подход)

Но для много вычислений на огромных данных обычно NewSQL не самый эффективный — он про OLTP на кластере, а не про массовые OLAP-сканы.

3) Какая модель распределённых вычислений справится лучше и почем

Лучший вариант для 1000 машин: MapReduce / DAG-подход (Spark-подобная модель)

Если говорить моделью, то в Big Data чаще всего побеждает:

DAG (Directed Acyclic Graph) вычислений, где задача разбивается на этапы,

данные режутся на партиции и считаются параллельно,

результаты шага переходят в следующий шаг.

Это то, что делает Apache Spark (и похожие движки).

Почему это хорошо:

отлично масштабируется по числу машин

выдерживает падения нод (за счёт пересчёта партиций)

подходит и для SQL-аналитики, и для ETL, и для ML

умеет кэшировать промежуточные результаты 

Если нужно именно SQL на кластере для интерактива

Тогда лучше:

MPP SQL-движок

Логика: запрос делится на куски - выполняется параллельно на нодах - результат собирается.

Это быстрее для аналитических запросов по таблицам, чем общий MapReduce, потому что оптимизатор под SQL.

Если данные приходят потоком и нужно считать на лету

Тогда нужна модель:

stream processing (микробатчи/потоковые окна

Подходят движки типа Flink/Spark Streaming (идея - постоянно считать агрегаты по окнам времени).

4) Итог: 

Критерий выбора СУБД: прежде всего тип нагрузки (OLAP vs OLTP), затем масштабируемость по горизонтали, скорость сканирования/агрегаций, модель распределения данных, SLA, отказоустойчивость, стоимость хранения.

Лучшая модель распределённых вычислений на 1000 машин:

для массовых вычислений и ETL - DAG/MapReduce-подход (Spark-подобная модель), потому что он устойчив к сбоям и эффективно распараллеливает вычисления на больших объёмах;

для быстрых интерактивных SQL-запросов - MPP-распределённый SQL (колоночная аналитическая СУБД), потому что оптимизирован под запросы и агрегации.
